from optomatic.worker import Worker
from optomatic.experiment import find_experiment_files, load_experiment_file
#from parameters import *
#from objective import X, y, objective
import user
import argparse
import sys
import logging
logger = logging.getLogger(__name__)




parser = argparse.ArgumentParser(description='Get new parameters from database and compute their corresponding score.')
parser.add_argument('--port', required=False, default='27017',
                    help='MongoDB host port (default: 27017).')
parser.add_argument('--host', required=False, default='localhost',
                    help='MongDB host address (default: localhost).')
parser.add_argument('-s', '--single-mode', required=False, const=True, action='store_const',
                    help='Enable single experiment mode (waits for new jobs to be inserted in db).')
parser.add_argument('-d', '--definition-file', required=False,
                    help='The name of the experiment definition file to use (when set, enables --single-mode).')
parser.add_argument('-P', '--project-name', required=False,
                    help='Project name to use for experiments (when set, enables --single-mode, requires --experiment-name).')
parser.add_argument('-E', '--experiment-name', required=False,
                    help='Experiment name to use for jobs (when set, enables --single-mode, requires --project-name).')

args = parser.parse_args()

# Sanity checks...
if args.project_name is not None and args.experiment_name is None:
    logger.critical('ERROR: got project-name but no experiment-name!')
    sys.exit(1)

if args.experiment_name is not None and args.project_name is None:
    logger.critical('ERROR: got experiment-name but no project-name!')
    sys.exit(1)

try:
    args.port = int(args.port)
except ValueError:
    logger.critical('ERROR: got non-integer port number!')
    sys.exit(1)

# Check if we should implicitly set single_mode...
if args.project_name is not None or args.definition_file is not None:
    args.single_mode = True

# Without a definitions file we just find all *.experiment files in cwd...
if args.definition_file is None:
    expt_files = find_experiment_files()
else:
    expt_files = [args.definition_file]

if args.single_mode is not None:
    logger.info('Running in recurrent single mode (will wait for new jobs)...')
    loop = True
else:
    logger.info('Running in multi-experiment mode (reads multiple experiment names from *.experiment files)...')
    loop = False


# Loop over experiment files (generated by coordinator.py)
# read each one: extract the project and experiment names,
# then launch a Worker instance on the experiment.
for expt_file in expt_files:

    logger.info('reading {} experiment definition file'.format(expt_file))
    dat = load_experiment_file(expt_file)

    project_name = dat['project']
    experiment_name = dat['experiment']

    # we stored the name of the classifier in the experiment name
    # delimited by a colon: get that name and use it to decide which
    # clf object to pass to Worker.
    clf_name = experiment_name.split(':')[0]
    clf = user.clfs[clf_name]

    logger.info("starting worker on project {}, experiment {}".format(project_name, experiment_name))
    
    # Note: we use loop_forever=False here since we want this worker to compute on the number
    # of (currently) queued jobs in the experiment and then exit, to allow a new Worker object
    # to do the next experiment (if there is one).
    w = Worker(project_name, experiment_name, clf, user.X, user.y, user.objective, 
                   host=args.host, port=args.port, loop_forever=loop)
    w.start_worker()

